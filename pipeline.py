from parser_agent.parser import parse_natural_language
from intent_classifier.classifier import classify_intent
from schema_mapper.mapper import map_to_schema
from query_generator.generator import generate_sql

def nl_to_sql(query: str) -> str:
    print(f"\nğŸ” Input Query: {query}")

    # Step 1: Parse the query
    parsed = parse_natural_language(query)
    print(f"ğŸ§  Parsed Output: {parsed}")

    # Step 2: Classify intent
    intent = classify_intent(parsed)
    print(f"ğŸ¯ Intent Detected: {intent}")

    # Step 3: Map to schema
    nouns = parsed.get("columns", []) + list(parsed.get("filters", {}).keys())
    schema = map_to_schema(nouns, parsed)
    print(f"ğŸ—‚ï¸ Schema Mapping: {schema}")

    # Step 4: Construct SQL
    # Pass both filters and function information
    filters = parsed.get("filters", {})
    if "function" in parsed:
        filters["function"] = parsed["function"]
    
    # Pass joins information
    joins = parsed.get("joins", [])
    
    # Pass group_by and having information
    group_by = parsed.get("group_by")
    having = parsed.get("having", {})
    
    # Pass subqueries information
    subqueries = parsed.get("subqueries", [])
    
    # Pass window functions information
    window_functions = parsed.get("window_functions", [])
    
    # Pass CTEs information
    ctes = parsed.get("ctes", [])
    
    # Pass advanced aggregations information
    advanced_aggregations = parsed.get("advanced_aggregations", [])
    
    sql = generate_sql(intent, schema["tables"], schema["columns"], filters, joins, group_by, having, subqueries, window_functions, ctes, advanced_aggregations)
    print(f"ğŸ’¡ Generated SQL: {sql}")

    return sql

if __name__ == "__main__":
    sample_query = "Show employees with rollup"
    nl_to_sql(sample_query)